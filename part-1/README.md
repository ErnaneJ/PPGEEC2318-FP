# Trabalho Final â€” Parte 1  
## ClassificaÃ§Ã£o de Imagens com CNNs (Intel Image Dataset)

- Ernane Ferreira Rocha Junior  
- Quelita MÃ­riam Nunes Ferraz

## ğŸ“ Estrutura do Projeto

```bash
part-1/
â”‚
â”œâ”€â”€ download-dataset.py/          # Script para download automÃ¡tico do Intel Image Dataset 
â”œâ”€â”€ part1_base_model.ipynb/       # Etapas do experimento, modelos e avaliaÃ§Ãµes 
â””â”€â”€ README.md/                    # DocumentaÃ§Ã£o do projeto
```

## ğŸ“Š Dataset: Intel Image Classification
Este projeto utiliza o conjunto de dados Intel Image Classification, originalmente disponibilizado por Puneet Bansal no [Kaggle](https://www.kaggle.com/datasets/puneet6060/intel-image-classification).

O dataset contÃ©m cerca de 25.000 imagens coloridas com resoluÃ§Ã£o padrÃ£o de 150x150 pixels. As imagens representam seis categorias distintas de ambientes naturais, conforme listadas abaixo:

* buildings â€“ imagens de prÃ©dios e construÃ§Ãµes urbanas
* forest â€“ paisagens de floresta
* glacier â€“ formaÃ§Ãµes de gelo e geleiras
* mountain â€“ imagens de montanhas
* sea â€“ paisagens marÃ­timas e costeiras
* street â€“ cenas urbanas de ruas

### ğŸ“ Estrutura dos Dados
O conjunto estÃ¡ organizado em trÃªs subconjuntos principais:

```bash
intel-image-classification/
â”‚
â”œâ”€â”€ seg_train/        # Dados de treino (~14.000 imagens)
â”‚   â”œâ”€â”€ buildings/
â”‚   â”œâ”€â”€ forest/
â”‚   â”œâ”€â”€ glacier/
â”‚   â”œâ”€â”€ mountain/
â”‚   â”œâ”€â”€ sea/
â”‚   â””â”€â”€ street/
â”‚
â”œâ”€â”€ seg_test/         # Dados de teste (~3.000 imagens rotuladas)
â”‚   â”œâ”€â”€ buildings/
â”‚   â”œâ”€â”€ forest/
â”‚   â”œâ”€â”€ glacier/
â”‚   â”œâ”€â”€ mountain/
â”‚   â”œâ”€â”€ sea/
â”‚   â””â”€â”€ street/
â”‚
â””â”€â”€ seg_pred/         # Dados de prediÃ§Ã£o (~7.000 imagens sem rÃ³tulo)
```

---

## ğŸ”¬ Etapas do Projeto

### ğŸ”¹ 1. Modelo Base (SimpleCNN)

- Estrutura CNN simples com camadas convolucionais, pooling e totalmente conectadas.
- Usado como baseline, ou seja, o resultado deste modelo Ã© utilizado para comparaÃ§Ãµes futuras para ver se houve melhora ou piora.

### ğŸ”¸ 2. Modelo Base + VariaÃ§Ãµes de `n_features`

- Experimentos com diferentes larguras de rede alterando o parÃ¢metro `n_feature` (nÃºmero de filtros).
- ComparaÃ§Ã£o dos efeitos de poucos e muitos filtros nas camadas convolucionais.
- Objetivo desta etapa Ã© investigar como a capacidade do modelo (o nÃºmero de features que ele pode aprender) afeta a performance na acurÃ¡cia.

### ğŸ”¹ 3. Modelo Base + Blocos

- Utiliza a arquitetura base e adiciona blocos de regularizaÃ§Ã£o apÃ³s as camadas de convoluÃ§Ã£o.
- Testar se tÃ©cnicas de regularizaÃ§Ã£o poderiam combater o overfitting observado no modelo base.

### ğŸ”¸ 4. Nosso Modelo: EfficientStrideCNN

- Modelo personalizado com uso eficiente de **strides** ao invÃ©s de pooling para reduzir a dimensÃ£o dos mapas de features.
- Otimizado para reduzir a complexidade e aumentar a performance.
- Implementado dentro da classe `Architecture`, que permite modularidade e troca de modelos.
- Avaliado com mÃ©tricas de precisÃ£o, perda e visualizaÃ§Ã£o da **matriz de confusÃ£o**.

---

## ğŸ“Š AvaliaÃ§Ã£o dos Resultados

Todos os modelos foram treinados por 10 Ã©pocas. 

### AcurÃ¡cia de validaÃ§Ã£o e GeneralizaÃ§Ã£o no conjunto de teste:

Foram treinados e avaliados quatro modelos distintos, variando a arquitetura e o nÃºmero de filtros. A performance de cada modelo foi medida pela perda (loss) de validaÃ§Ã£o e por um relatÃ³rio de classificaÃ§Ã£o detalhado ao final de 10 Ã©pocas.

| Modelo | Val Loss | ParÃ¢metro | AcurÃ¡cia (Teste) |
|--------|----------|-----------|------------------|
| Menos filtros 8-16-32	| 0.5781 | 1.334.038 | 81.9% |
| Modelo Base 16-32-64	| 0.5855 | 2.678.694 | 80.8% |
| Modelo com Conv. Kernel 5 | 0.6428 | 5.402.566 | 79.2% |
| Mais filtros 32-64-128 | 0.6531 | 50.726 | 78.4% |
| Base + Blocos (BN/Dropout) | 0.7726 | 2.678.918 | 74.2% |

- O modelo com menos filtros (8-16-32) treinou com eficiÃªncia, alcanÃ§ou menor perda de validaÃ§Ã£o e a maior acurÃ¡cia no conjunto de testes. Isso indica que ele encontrou um Ã³timo equilÃ­brio, aprendendo os padrÃµes necessÃ¡rios sem memorizar o ruÃ­do do conjunto de treino (overfitting).

- O aumento no nÃºmero de filtros piorou a performace, causando um overfitting mais acentuado.

- A adiÃ§Ã£o de blocos de regularizaÃ§Ã£o apÃ³s as camadas de convoluÃ§Ã£o degradou significativamente a performance. Isso sugere que a regularizaÃ§Ã£o aplicada foi forte demais, levando o modelo a um estado de underfitting (nÃ£o conseguiu aprender o suficiente nem mesmo do conjunto de treino).

- O modelo com kernel 5x5 apresentou um resultado intermediÃ¡rio. Embora seja uma tÃ©cnica vÃ¡lida, para este problema especÃ­fico nÃ£o superou a abordagem mais simples e eficiente do modelo com menos filtros.

a menor perda de validaÃ§Ã£o (0.5781), indicando a melhor capacidade de generalizaÃ§Ã£o no conjunto de teste entre os modelos avaliados. A acurÃ¡cia geral deste modelo foi de 81,9%. Os modelos "Base" e "Mais filtros" apresentaram overfitting mais acentuado, como pode ser visto nos grÃ¡ficos de perda, onde a perda de treinamento continua a diminuir enquanto a de validaÃ§Ã£o estabiliza ou aumenta.

### AnÃ¡lise visual com matriz de confusÃ£o:

Para cada um dos cinco modelos, foram gerados um relatÃ³rio de classificaÃ§Ã£o e uma matriz de confusÃ£o. A anÃ¡lise desses resultados permite uma compreensÃ£o mais profunda da performance de cada classe.

* Modelo "Menos filtros 8-16-32" (Melhor Performance):

- AcurÃ¡cia: 81,9%
- Destaques: Apresentou excelente performance para a classe forest (97% de recall) e street (88% de recall). A classe com maior dificuldade de classificaÃ§Ã£o foi glacier, com 74% de recall.

* Modelo "Base + Blocos (BN/Dropout)":

- AcurÃ¡cia: 74,2%
- Destaques: Este modelo, apesar da regularizaÃ§Ã£o com Batch Normalization e Dropout, teve a menor acurÃ¡cia. Ele se destacou na classe forest (97% de recall) mas teve dificuldades com buildings (63% de recall) e mountain (59% de recall).

A anÃ¡lise visual das matrizes de confusÃ£o confirma que a classe glacier Ã© frequentemente confundida com buildings e mountain na maioria dos modelos, indicando uma semelhanÃ§a visual que dificulta a distinÃ§Ã£o pela CNN.

### VisualizaÃ§Ã£o de ativaÃ§Ã£o de filtros internos com hooks para compreensÃ£o interpretÃ¡vel da CNN

Para entender o que a CNN aprende em suas camadas intermediÃ¡rias, foram utilizados hooks para capturar e visualizar os mapas de ativaÃ§Ã£o das camadas convolucionais.

O processo consiste em:

- Registrar um "gancho" (hook): Uma funÃ§Ã£o Ã© registrada em uma camada especÃ­fica (ex: conv2). Essa funÃ§Ã£o salva a saÃ­da da camada (os mapas de ativaÃ§Ã£o) em um dicionÃ¡rio sempre que a rede processa uma imagem.

- Passar um lote de imagens: Um lote de imagens Ã© processado pelo modelo no modo de avaliaÃ§Ã£o.

- Visualizar as ativaÃ§Ãµes: Os mapas de ativaÃ§Ã£o de uma imagem especÃ­fica do lote sÃ£o extraÃ­dos. Para cada filtro da camada, o mapa de ativaÃ§Ã£o Ã© exibido como uma imagem em tons de verde, onde Ã¡reas mais claras indicam maior ativaÃ§Ã£o.

Essa tÃ©cnica oferece uma visÃ£o interpretÃ¡vel do que cada filtro estÃ¡ detectando. Por exemplo, alguns filtros podem se especializar em detectar bordas, texturas especÃ­ficas (como folhagens ou rochas) ou formas mais complexas. As ativaÃ§Ãµes do modelo "Meu Modelo com ConvoluÃ§Ã£o Kernel 5" foram exploradas, mostrando os diferentes features que a rede aprendeu a identificar.

---

## ğŸ§ª ExecuÃ§Ã£o

1. Execute `download-dataset.py` para baixar o dataset.
2. Abra o notebook `part1_base_model.ipynb`.
3. Siga as cÃ©lulas sequencialmente para treinar e avaliar os modelos.

---

## ğŸ“Œ ObservaÃ§Ãµes Finais

Este projeto Ã© parte do projeto final da disciplina Aprendizado de MÃ¡quina de Mestrado em Engenharia da ComputaÃ§Ã£o e ElÃ©trica da UFRN, contendo uso do [notebook](https://github.com/ivanovitchm/PPGEEC2318) disponibilizado pelo professor para a tarefa. Tem como objetivo comparar diferentes abordagens de redes neurais convolucionais aplicadas Ã  tarefa de classificaÃ§Ã£o de imagens naturais. O modelo final reflete uma proposta autoral otimizada com base nos experimentos anteriores.

